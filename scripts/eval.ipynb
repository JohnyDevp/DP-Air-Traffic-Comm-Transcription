{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ATCO2-ASRdataset-v1_final/DATA/LSZH_ZURICH_ApronN_121_85MHz_20210414_140149.wav 0 1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "all = json.load(open('/home/johnny/Code/DP-Air-Traffic-Comm-Transcription/data/atco/PROMPT/metadata_en_zurich_test.json'))\n",
    "wer_prop = open('metadata_en_zurich_tmp.txt').readlines()\n",
    "count = 0\n",
    "for line in wer_prop:\n",
    "    line = re.sub(r'\\s+', ' ', line).strip()\n",
    "    file_name = line.split()[0].replace('.xml', '.wav')\n",
    "    wer_count = int(line.split()[1])\n",
    "    for item in all:\n",
    "        if file_name in item['audio']:\n",
    "            # print(item['audio'])\n",
    "            s = sum([cal['val'] for cal in item['prompt-data']['long_callsigns']])\n",
    "            if (s != wer_count):\n",
    "                print(f\"Error: {file_name} {s} {wer_count}\")\n",
    "    # count += wer_count\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "metric = evaluate.load(\"wer\")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PrepareDatasetAsInput:\n",
    "    \n",
    "    def __init__(self, feature_extractor, tokenizer_en, tokenizer_fr):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.tokenizer_en = tokenizer_en\n",
    "        self.tokenizer_fr = tokenizer_fr\n",
    "            \n",
    "    def prepare_dataset(self, batch):\n",
    "        # load and resample audio data from 48 to 16kHz\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        # compute log-Mel input features from input audio array\n",
    "        batch[\"input_features\"] = self.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "        # encode target text to label ids **** CHANGED FROM **sentence** TO **transcription**\n",
    "        # if french, than use french tokenizer, english otherwise\n",
    "        tokenizer = self.tokenizer_en\n",
    "        if \"lang\" in batch:\n",
    "            if batch[\"lang\"] == \"fr\":\n",
    "                tokenizer = self.tokenizer_fr\n",
    "\n",
    "        batch[\"labels_fullts\"] = tokenizer(batch[\"full_ts\"]).input_ids\n",
    "        batch[\"labels_shortts\"] = tokenizer(batch[\"short_ts\"]).input_ids\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def prepare_dataset_self_prompt(self,batch):\n",
    "        # load and resample audio data from 48 to 16kHz\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        # compute log-Mel input features from input audio array\n",
    "        batch[\"input_features\"] = self.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "        # encode target text to label ids **** CHANGED FROM **sentence** TO **transcription**\n",
    "        # if french, than use french tokenizer, english otherwise\n",
    "        tokenizer = self.tokenizer_en\n",
    "        if \"lang\" in batch:\n",
    "            if batch[\"lang\"] == \"fr\":\n",
    "                tokenizer = self.tokenizer_fr\n",
    "        \n",
    "        # make prompt from the lables\n",
    "        batch['fullts_prompt_ids'] = self.tokenizer_en.get_prompt_ids(batch[\"full_ts\"]).tolist() # YOU NEED TO ADD TOLIST() because array cant be combined with list in the next lines\n",
    "        batch['shortts_prompt_ids'] = self.tokenizer_en.get_prompt_ids(batch[\"short_ts\"]).tolist() # YOU NEED TO ADD TOLIST() because array cant be combined with list in the next lines\n",
    "        \n",
    "        batch[\"labels_fullts\"] = tokenizer(batch[\"full_ts\"]).input_ids # building labels ids with prompt and tokens together\n",
    "        batch[\"labels_shortts\"] = tokenizer(batch[\"short_ts\"]).input_ids\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def prepare_dataset_with_prompt(self,batch):        \n",
    "        # load and resample audio data from 48 to 16kHz\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        # compute log-Mel input features from input audio array\n",
    "        features = self.feature_extractor(\n",
    "            audio[\"array\"], \n",
    "            sampling_rate=audio[\"sampling_rate\"],\n",
    "            truncation=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        # add input features to batch\n",
    "        batch[\"input_features\"] = features.input_features[0]\n",
    "        \n",
    "        # add attention mask to batch, potentially for data augmentation\n",
    "        batch['attention_mask'] = features.attention_mask[0]\n",
    "\n",
    "        # STORE THE CALLSIGNS FOR EVALUATION\n",
    "        if (\"prompt-data\" in batch):\n",
    "            batch['long_callsigns'] = batch['prompt-data']['long_callsigns']\n",
    "            batch['short_callsigns'] = batch['prompt-data']['short_callsigns']\n",
    "        else :\n",
    "            batch['long_callsigns'] = {}\n",
    "            batch['short_callsigns'] = {}\n",
    "            \n",
    "        # encode target text to label ids **** CHANGED FROM **sentence** TO **transcription**\n",
    "        # if french, than use french tokenizer, english otherwise\n",
    "        tokenizer = self.tokenizer_en\n",
    "        if \"lang\" in batch:\n",
    "            if batch[\"lang\"] == \"fr\":\n",
    "                tokenizer = self.tokenizer_fr\n",
    "\n",
    "        # encode prompts to prompt ids - we assume that the dataset has a column `\"prompt\"` that contains the prompt for each example\n",
    "        prompt_ids = tokenizer.get_prompt_ids(batch['prompt_fullts_AG']).tolist() # YOU NEED TO ADD TOLIST() because array cant be combined with list in the next lines\n",
    "\n",
    "        batch[\"labels\"] = prompt_ids + tokenizer(batch['full_ts']).input_ids # building labels ids with prompt and tokens together\n",
    "        batch['prompt_ids'] = prompt_ids # add the prompt ids to the batch\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMetrics:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def compute_metrics(self,pred_text, reference_text):\n",
    "        pred_ids = pred_text\n",
    "        label_ids = reference_text\n",
    "\n",
    "        # replace -100 with the pad_token_id\n",
    "        label_ids[label_ids == -100] = self.tokenizer.pad_token_id\n",
    "\n",
    "        # we do not want to group tokens when computing the metrics\n",
    "        pred_str = self.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = self.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    def compute_metrics2(self,pred_str,label_str):\n",
    "\n",
    "        wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "        return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data/en_ruzyne_test_ds'\n",
    "# model_def = './test3-tiny-prompt/checkpoint-980'\n",
    "# model_def = './checkpoint-980'\n",
    "model_def = 'openai/whisper-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(model_def).cuda()\n",
    "processor = WhisperProcessor.from_pretrained(model_def,language=\"English\", task=\"transcribe\")\n",
    "prepare_dataset = PrepareDatasetAsInput(processor.feature_extractor, processor.tokenizer, processor.tokenizer) #TODO handle FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|en|><|transcribe|><|notimestamps|>Radar CSA One Delta Zulu established\n",
      "CSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\n",
      "\n",
      "three four five six zero CSA One Delta Zulu  pekný deň<|endoftext|>\n",
      "<|en|><|transcribe|><|notimestamps|>Radar CSA One Delta Zulu established\n",
      "CSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\n",
      "\n",
      "three four five six zero CSA One Delta Zulu  pekný deň<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "a=processor.tokenizer.decode(torch.tensor([50259, 50359, 50363, 48444,   289,   383,  8886,  1485, 18183,  1176,\n",
    "        12845,  7545,   198,    34,  8886,  1485, 18183,  1176, 12845,   744,\n",
    "         1321,  3385, 15702,  1229,   716, 17877,   472,  1045,  1451, 26601,\n",
    "         1732,  2309,  4018,   198,   198, 27583,  1451,  1732,  2309,  4018,\n",
    "          383,  8886,  1485, 18183,  1176, 12845,   220,   520,  5457, 11822,\n",
    "          368,   129,   230, 50257]))\n",
    "print(a)\n",
    "b=processor.tokenizer.decode(torch.tensor([50259, 50359, 50363, 48444,   289,   383,  8886,  1485, 18183,  1176,\n",
    "         12845,  7545,   198,    34,  8886,  1485, 18183,  1176, 12845,   744,\n",
    "          1321,  3385, 15702,  1229,   716, 17877,   472,  1045,  1451, 26601,\n",
    "          1732,  2309,  4018,   198,   198, 27583,  1451,  1732,  2309,  4018,\n",
    "           383,  8886,  1485, 18183,  1176, 12845,   220,   520,  5457, 11822,\n",
    "           368,   129,   230, 50257]))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|en|><|transcribe|><|notimestamps|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(torch.tensor([50258, 50259, 50359, 50363]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.feature_extractor.padding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50259 50359 50363  9000   578 25866  9116  1246 14868  9436 18939  6244\n",
      " 50257     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0]\n"
     ]
    }
   ],
   "source": [
    "labels_ids=[50259, 50359, 50363,  9000,   578, 25866,  9116,  1246, 14868,  9436,\n",
    "        18939,  6244, 50257,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
    "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
    "         -100,  -100,  -100,  -100,  -100,  -100,  -100]\n",
    "\n",
    "attention_mask = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "print(np.where(np.array(attention_mask) == 1,labels_ids,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the parameters of model for correct working\n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None\n",
    "model.freeze_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f053b35f32c47f4890cf6034ca063cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_features', 'attention_mask', 'long_callsigns', 'short_callsigns', 'labels', 'prompt_ids'],\n",
      "    num_rows: 70\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# load and prepare the dataset\n",
    "dataset = load_from_disk(dataset_path)\n",
    "ds_ready = dataset.map(prepare_dataset.prepare_dataset_with_prompt, remove_columns=dataset.column_names, num_proc=1)\n",
    "# ds_ready = ds_ready.rename_columns({'labels_fullts':'labels','fullts_prompt_ids':'prompt_ids'})\n",
    "\n",
    "print(ds_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startofprev|> air france one zero eight zulu<|startoftranscript|><|en|><|transcribe|><|notimestamps|>air france one zero eight zulu standby now descend to descend flight level seven zero air france one zero eight zulu<|endoftext|>'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(ds_ready[2]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 3000])\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(dataset[0]['audio']['array'], padding='max_length',  return_tensors=\"pt\", truncation=False,  return_attention_mask=True, sampling_rate=16_000)\n",
    "print(inputs.input_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds_ready[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tokens = processor.tokenizer.convert_tokens_to_ids(['<|startoftranscript|>','<|en|>','<|transcribe|>','<|notimestamps|>'])\n",
    "prompt_features = [{'input_ids': batch['prompt_ids'][idx] + init_tokens} for idx,_ in enumerate(batch['prompt_ids'])]\n",
    "prompt_batch = processor.tokenizer.ppadding=\"longest\",ad(prompt_features, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ids = (ds_ready[0:4]['prompt_ids'][0] + init_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_150494/3792684042.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'decoder_input_ids': torch.tensor(prompt_batch['input_ids']).cuda(),\n"
     ]
    }
   ],
   "source": [
    "# PREPARE THE BATCH FOR GENERATE\n",
    "# we will create batch of four\n",
    "batch = {\n",
    "    'input_features': torch.tensor(batch['input_features']).cuda(),\n",
    "    'decoder_input_ids': torch.tensor(prompt_batch['input_ids']).cuda(),\n",
    "    'decoder_attention_mask': torch.tensor(np.where(prompt_batch['input_ids'] != 50257,1,0)).cuda(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50361, 21065, 10567,   665,  2446,  2665,  1100,  2475,    88,  6244,\n",
      "          286, 19198,  1045,  1451,  1411, 50258, 50259, 50359],\n",
      "       device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input_ids[0][0:18])\n",
    "print(decoder_attention_mask[0][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29]) tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27,  1,  1]], device='cuda:0')\n",
      " golf Yan\n",
      " Hotel Golf Yankee we appreciate the shortcut the Golf Yankee roger report your program in Bern\n"
     ]
    }
   ],
   "source": [
    "init_tokens = processor.tokenizer.convert_tokens_to_ids(['<|startoftranscript|>','<|en|>','<|transcribe|>','<|notimestamps|>'])\n",
    "\n",
    "idx=2\n",
    "padding = [50257 for _ in range(2)]\n",
    "input_features = torch.tensor(ds_ready[idx]['input_features']).unsqueeze(0).cuda()\n",
    "prompt_ids = np.array(ds_ready[idx]['prompt_ids'] + init_tokens + padding) # 50257 is the pad token id\n",
    "prompt_prompt = torch.tensor(ds_ready[idx]['prompt_ids']).cuda()\n",
    "\n",
    "\n",
    "decoder_input_ids = torch.tensor(prompt_ids).unsqueeze(0).cuda()\n",
    "decoder_attention_mask = torch.tensor(np.where(prompt_ids != 50257,1,0)).unsqueeze(0).cuda()\n",
    "decoder_position_ids = torch.arange(1, len(prompt_ids)+1).unsqueeze(0).cuda()\n",
    "#for padding set decoder_position_ids to 0\n",
    "decoder_position_ids[0][len(ds_ready[idx]['prompt_ids'] + init_tokens):] = 1\n",
    "\n",
    "print(decoder_input_ids.shape, decoder_position_ids)\n",
    "out2 = model.generate(\n",
    "    input_features=input_features,\n",
    "    decoder_input_ids=decoder_input_ids,\n",
    "    decoder_attention_mask=decoder_attention_mask,\n",
    "    decoder_position_ids=decoder_position_ids,\n",
    "    # attention_mask=decoder_attention_mask\n",
    "    # prompt_ids=torch.tensor(ds_ready[0]['prompt_ids']).cuda()\n",
    ").detach().cpu()\n",
    "print(processor.decode(out2[0],skip_special_tokens=True))\n",
    "\n",
    "outx = model.generate(\n",
    "    input_features=input_features,\n",
    "    # decoder_input_ids=decoder_input_ids[1][0:18][None],\n",
    "    # decoder_attention_mask=decoder_attention_mask,\n",
    "    # attention_mask=decoder_attention_mask\n",
    "    prompt_ids=prompt_prompt\n",
    ").detach().cpu()\n",
    "print(processor.decode(outx[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hotel Golf Yankee we appreciate the shortcut the Golf Yankee roger report your program in Bern\n"
     ]
    }
   ],
   "source": [
    "print(processor.decode(out2[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tokens = processor.tokenizer.convert_tokens_to_ids(['<|startoftranscript|>','<|en|>','<|transcribe|>','<|notimestamps|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vacate bravo one copy traffic three four left cleared to land Qantas Six Forty Two on a spot 93 vacate now via bravo one\n",
      " vacate bravo one copy traffic three four left cleared to land Qantas Six Forty Two on a spot 93 vacate now via bravo one\n"
     ]
    }
   ],
   "source": [
    "# test modelu s promptem (1 nebo 10 epoch vyjde na stejno zda se)\n",
    "dec_qwd=np.array(ds_ready[3]['prompt_ids']+init_tokens+ [50257 for _ in range(20)])\n",
    "mask=np.where(dec_qwd != 50257,1,0)\n",
    "\n",
    "out2 = model.generate(\n",
    "    torch.tensor(ds_ready[3]['input_features']).unsqueeze(0).cuda(),\n",
    "    decoder_input_ids=torch.tensor(dec_qwd).unsqueeze(0).cuda(),\n",
    "    decoder_attention_mask=torch.tensor(mask).unsqueeze(0).cuda(),\n",
    "    \n",
    "    # prompt_ids=torch.tensor(ds_ready[3]['prompt_ids']).cuda()\n",
    ").detach().cpu()\n",
    "print(processor.decode(out2[0]))\n",
    "\n",
    "out2 = model.generate(\n",
    "    torch.tensor(ds_ready[3]['input_features']).unsqueeze(0).cuda(),\n",
    "    # decoder_input_ids=torch.tensor(ds_ready[3]['prompt_ids']+init_tokens).unsqueeze(0).cuda()\n",
    "    prompt_ids=torch.tensor(ds_ready[3]['prompt_ids']).cuda()\n",
    ").detach().cpu()\n",
    "print(processor.decode(out2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Go to the taxi we appreciate the drop-up. The coffee and the rock show report you program in burn\n",
      "real\n",
      "ruwnay three four left cleared to land Jetstar Four Twenty One\n"
     ]
    }
   ],
   "source": [
    "# test modelu, kdy je vstup a prompt jsou od jinych nahravek\n",
    "# vysledek - neni to uplne tak, ze ten model prepsal ten prompt, ale dost se to blizi tomu\n",
    "out3 = model.generate(\n",
    "    torch.tensor(ds_ready[2]['input_features']).unsqueeze(0).cuda(),\n",
    "    prompt_ids=torch.tensor(ds_ready[0]['prompt_ids']).cuda()\n",
    ").detach().cpu()\n",
    "print(processor.decode(out3[0]))\n",
    "print('real')\n",
    "print(processor.decode(ds_ready[1]['labels'],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m batch_decoder_inputs = processor.tokenizer.pad({\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m: ds_ready[\u001b[32m0\u001b[39m:\u001b[32m2\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mprompt_ids\u001b[39m\u001b[33m'\u001b[39m]}, padding=\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Generate\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_ready\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_features\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_decoder_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_decoder_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Important for handling padding\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/generation_whisper.py:774\u001b[39m, in \u001b[36mWhisperGenerationMixin.generate\u001b[39m\u001b[34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, time_precision_features, return_token_timestamps, return_segments, return_dict_in_generate, force_unique_generate_call, **kwargs)\u001b[39m\n\u001b[32m    765\u001b[39m             proc.set_begin_index(decoder_input_ids.shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    767\u001b[39m \u001b[38;5;66;03m# 6.6 Run generate with fallback\u001b[39;00m\n\u001b[32m    768\u001b[39m (\n\u001b[32m    769\u001b[39m     seek_sequences,\n\u001b[32m    770\u001b[39m     seek_outputs,\n\u001b[32m    771\u001b[39m     should_skip,\n\u001b[32m    772\u001b[39m     do_condition_on_prev_tokens,\n\u001b[32m    773\u001b[39m     model_output_type,\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    775\u001b[39m \u001b[43m    \u001b[49m\u001b[43msegment_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43msegment_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcur_bsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_bsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_idx_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseek\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_segment_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_timestamps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_condition_on_prev_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_condition_on_prev_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_shortform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;66;03m# 6.7 In every generated sequence, split by timestamp tokens and extract segments\u001b[39;00m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, seek_sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(seek_sequences):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/generation_whisper.py:995\u001b[39m, in \u001b[36mWhisperGenerationMixin.generate_with_fallback\u001b[39m\u001b[34m(self, segment_input, decoder_input_ids, cur_bsz, batch_idx_map, seek, num_segment_frames, max_frames, temperatures, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_token_timestamps, do_condition_on_prev_tokens, is_shortform, batch_size, attention_mask, kwargs)\u001b[39m\n\u001b[32m    992\u001b[39m         seek_sequence = seek_sequence[:-num_paddings]\n\u001b[32m    994\u001b[39m \u001b[38;5;66;03m# check which sequences in batch need fallback & which should be skipped\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m \u001b[43mneeds_fallback\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, should_skip[i] = \u001b[38;5;28mself\u001b[39m._need_fallback(\n\u001b[32m    996\u001b[39m     seek_sequence,\n\u001b[32m    997\u001b[39m     seek_outputs,\n\u001b[32m    998\u001b[39m     i,\n\u001b[32m    999\u001b[39m     logits_processor,\n\u001b[32m   1000\u001b[39m     generation_config,\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28mself\u001b[39m.config.vocab_size,\n\u001b[32m   1002\u001b[39m     temperature,\n\u001b[32m   1003\u001b[39m )\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# remove eos token\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seek_sequence[-\u001b[32m1\u001b[39m] == generation_config.eos_token_id:\n",
      "\u001b[31mIndexError\u001b[39m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Prepare decoder prompts (pad them to the same length)\n",
    "batch_decoder_inputs = processor.tokenizer.pad({\"input_ids\": ds_ready[0:2]['prompt_ids']}, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "outputs = model.generate(\n",
    "    input_features=torch.tensor(ds_ready[0:1]['input_features']).cuda(),\n",
    "    decoder_input_ids=batch_decoder_inputs[\"input_ids\"].cuda(),\n",
    "    decoder_attention_mask=batch_decoder_inputs[\"attention_mask\"],  # Important for handling padding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftranscript|><|notimestamps|>Radar CSA One Delta Zulu established\n",
      "CSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\n",
      "\n",
      "three four five six zero CSA One Delta Zulu  pekný deň<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# print(processor.decode(out1[0]))\n",
    "print(processor.decode(ds_ready[0]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        batch[\"labels\"] = labels_batch\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ds_ready, batch_size=3, collate_fn=data_collator)\n",
    "metr = ComputeMetrics(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(input_features).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over batches\n",
    "all_preds = []\n",
    "all_lables = []\n",
    "for batch in dataloader:\n",
    "    input_features = batch[\"input_features\"].cuda()\n",
    "    out = model.generate(input_features).detach().cpu()\n",
    "    all_preds.extend(processor.batch_decode(out, skip_special_tokens=True))\n",
    "    all_lables.extend(processor.batch_decode(batch[\"labels\"]['input_ids'], skip_special_tokens=True))\n",
    "    # Free memory\n",
    "    del batch\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmetr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_lables\u001b[49m\u001b[43m)\u001b[49m    \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mComputeMetrics.compute_metrics\u001b[39m\u001b[34m(self, pred_text, reference_text)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# we do not want to group tokens when computing the metrics\u001b[39;00m\n\u001b[32m     13\u001b[39m pred_str = \u001b[38;5;28mself\u001b[39m.tokenizer.batch_decode(pred_ids, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m label_str = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m wer = \u001b[32m100\u001b[39m * metric.compute(predictions=pred_str, references=label_str)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mwer\u001b[39m\u001b[33m\"\u001b[39m: wer}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3821\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.batch_decode\u001b[39m\u001b[34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[39m\n\u001b[32m   3796\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbatch_decode\u001b[39m(\n\u001b[32m   3797\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   3798\u001b[39m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[33m\"\u001b[39m\u001b[33mnp.ndarray\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtorch.Tensor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtf.Tensor\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   3801\u001b[39m     **kwargs,\n\u001b[32m   3802\u001b[39m ) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m   3803\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[33;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[32m   3805\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3818\u001b[39m \u001b[33;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[32m   3819\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   3820\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m-> \u001b[39m\u001b[32m3821\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3822\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3823\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3824\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3825\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3826\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3827\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[32m   3828\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py:723\u001b[39m, in \u001b[36mWhisperTokenizer.decode\u001b[39m\u001b[34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, output_offsets, time_precision, decode_with_timestamps, normalize, basic_normalize, remove_diacritics, **kwargs)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\n\u001b[32m    674\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    675\u001b[39m     token_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     **kwargs,\n\u001b[32m    685\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    686\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[33;03m    Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[33;03m    tokens and clean up tokenization spaces.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    721\u001b[39m \u001b[33;03m        `str`: The decoded sentence.\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m     filtered_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_preprocess_token_ids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m     text = \u001b[38;5;28msuper\u001b[39m().decode(\n\u001b[32m    729\u001b[39m         filtered_ids,\n\u001b[32m    730\u001b[39m         skip_special_tokens=skip_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m    735\u001b[39m         **kwargs,\n\u001b[32m    736\u001b[39m     )\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decode_with_timestamps:\n\u001b[32m    738\u001b[39m         \u001b[38;5;66;03m# legacy method to decode timestamps when not included in the tokenizer vocabulary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py:666\u001b[39m, in \u001b[36mWhisperTokenizer._preprocess_token_ids\u001b[39m\u001b[34m(self, token_ids, skip_special_tokens)\u001b[39m\n\u001b[32m    664\u001b[39m     prompt_token_id = \u001b[38;5;28mself\u001b[39m.convert_tokens_to_ids(\u001b[33m\"\u001b[39m\u001b[33m<|startofprev|>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    665\u001b[39m     decoder_start_token_id = \u001b[38;5;28mself\u001b[39m.convert_tokens_to_ids(\u001b[33m\"\u001b[39m\u001b[33m<|startoftranscript|>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     token_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strip_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_start_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py:886\u001b[39m, in \u001b[36mWhisperTokenizer._strip_prompt\u001b[39m\u001b[34m(self, token_ids, prompt_token_id, decoder_start_token_id)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token_ids:\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m token_ids\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m has_prompt = \u001b[43mtoken_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m == prompt_token_id\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_prompt:\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_start_token_id \u001b[38;5;129;01min\u001b[39;00m token_ids:\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "metr.compute_metrics(all_preds, all_lables)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 76.61662817551964}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.compute_metrics2(all_preds, all_lables)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = metr.compute_metrics(out[0].unsqueeze(0), batch[\"labels\"]['input_ids'][0].unsqueeze(0))\n",
    "val1 = metr.compute_metrics(out[1].unsqueeze(0), batch[\"labels\"]['input_ids'][1].unsqueeze(0))\n",
    "val2= metr.compute_metrics(out[2].unsqueeze(0), batch[\"labels\"]['input_ids'][2].unsqueeze(0))\n",
    "print(val,val1,val2,(val1['wer']+val2['wer']+val['wer'])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.tensor(ds_ready['input_features'][:5]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model.generate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del batch\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Radar CSA One Delta Zulu established\\nCSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\\n\\nthree four five six zero CSA One Delta Zulu  pekný deň'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(ds_ready[0]['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 42])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Radar CC1DZ, established CC1DZ, roger, contact roger tower 134.560 134.560, CC1DZ, take me again'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr = ComputeMetrics(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9654,   289, 12630,    16,    35,    57,    11,  7545, 12630,    16,\n",
       "           35,    57,    11,   744,  1321,    11,  3385,   744,  1321, 10567,\n",
       "         3705,    19,    13,    20,  4550,  3705,    19,    13,    20,  4550,\n",
       "           11, 12630,    16,    35,    57,    11,   747,   385,   797, 50257,\n",
       "        50257, 50257], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50258, 50363, 48444,   289,   383,  8886,  1485, 18183,  1176, 12845,\n",
       "         7545,   198,    34,  8886,  1485, 18183,  1176, 12845,   744,  1321,\n",
       "         3385, 15702,  1229,   716, 17877,   472,  1045,  1451, 26601,  1732,\n",
       "         2309,  4018,   198,   198, 27583,  1451,  1732,  2309,  4018,   383,\n",
       "         8886,  1485, 18183,  1176, 12845,   220,   520,  5457, 11822,   368,\n",
       "          129,   230, 50257])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(ds_ready[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 93.54838709677419}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.compute_metrics(out[0].unsqueeze(0), torch.tensor(ds_ready[0]['labels']).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = processor.tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "label_test = processor.tokenizer.batch_decode(ds_ready['labels'][:3], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 78.37837837837837}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.compute_metrics2(out_test,label_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
