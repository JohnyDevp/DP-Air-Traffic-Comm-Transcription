{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import WhisperTokenizer, WhisperProcessor, WhisperForConditionalGeneration\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "metric = evaluate.load(\"wer\")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PrepareDatasetAsInput:\n",
    "    \n",
    "    def __init__(self, feature_extractor, tokenizer_en, tokenizer_fr):\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.tokenizer_en = tokenizer_en\n",
    "        self.tokenizer_fr = tokenizer_fr\n",
    "            \n",
    "    def prepare_dataset(self, batch):\n",
    "        # load and resample audio data from 48 to 16kHz\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        # compute log-Mel input features from input audio array\n",
    "        batch[\"input_features\"] = self.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "        # encode target text to label ids **** CHANGED FROM **sentence** TO **transcription**\n",
    "        # if french, than use french tokenizer, english otherwise\n",
    "        tokenizer = self.tokenizer_en\n",
    "        if \"lang\" in batch:\n",
    "            if batch[\"lang\"] == \"fr\":\n",
    "                tokenizer = self.tokenizer_fr\n",
    "\n",
    "        batch[\"labels_fullts\"] = tokenizer(batch[\"full_ts\"]).input_ids\n",
    "        batch[\"labels_shortts\"] = tokenizer(batch[\"short_ts\"]).input_ids\n",
    "\n",
    "        return batch\n",
    "    \n",
    "    def prepare_dataset_self_prompt(self,batch):\n",
    "        # load and resample audio data from 48 to 16kHz\n",
    "        audio = batch[\"audio\"]\n",
    "\n",
    "        # compute log-Mel input features from input audio array\n",
    "        batch[\"input_features\"] = self.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "        # encode target text to label ids **** CHANGED FROM **sentence** TO **transcription**\n",
    "        # if french, than use french tokenizer, english otherwise\n",
    "        tokenizer = self.tokenizer_en\n",
    "        if \"lang\" in batch:\n",
    "            if batch[\"lang\"] == \"fr\":\n",
    "                tokenizer = self.tokenizer_fr\n",
    "        \n",
    "        # make prompt from the lables\n",
    "        batch['fullts_prompt_ids'] = self.tokenizer_en.get_prompt_ids(batch[\"full_ts\"]).tolist() # YOU NEED TO ADD TOLIST() because array cant be combined with list in the next lines\n",
    "        batch['shortts_prompt_ids'] = self.tokenizer_en.get_prompt_ids(batch[\"short_ts\"]).tolist() # YOU NEED TO ADD TOLIST() because array cant be combined with list in the next lines\n",
    "        \n",
    "        batch[\"labels_fullts\"] = tokenizer(batch[\"full_ts\"]).input_ids # building labels ids with prompt and tokens together\n",
    "        batch[\"labels_shortts\"] = tokenizer(batch[\"short_ts\"]).input_ids\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMetrics:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def compute_metrics(self,pred_text, reference_text):\n",
    "        pred_ids = pred_text\n",
    "        label_ids = reference_text\n",
    "\n",
    "        # replace -100 with the pad_token_id\n",
    "        label_ids[label_ids == -100] = self.tokenizer.pad_token_id\n",
    "\n",
    "        # we do not want to group tokens when computing the metrics\n",
    "        pred_str = self.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "        label_str = self.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "        wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "        return {\"wer\": wer}\n",
    "\n",
    "    def compute_metrics2(self,pred_str,label_str):\n",
    "\n",
    "        wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "        return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data/atco/en_ruzyne_test_ds'\n",
    "# model_def = './test3-tiny-prompt/checkpoint-980'\n",
    "model_def = './checkpoint-980'\n",
    "# model_def = 'openai/whisper-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhisperForConditionalGeneration.from_pretrained(model_def).cuda()\n",
    "processor = WhisperProcessor.from_pretrained(model_def)\n",
    "prepare_dataset = PrepareDatasetAsInput(processor.feature_extractor, processor.tokenizer, processor.tokenizer) #TODO handle FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the parameters of model for correct working\n",
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee660158f58340ffa4a5a918396f67c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_features', 'prompt_ids', 'shortts_prompt_ids', 'labels', 'labels_shortts'],\n",
      "    num_rows: 70\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# load and prepare the dataset\n",
    "dataset = load_from_disk(dataset_path)\n",
    "ds_ready = dataset.map(prepare_dataset.prepare_dataset_self_prompt, remove_columns=dataset.column_names, num_proc=1)\n",
    "ds_ready = ds_ready.rename_columns({'labels_fullts':'labels','fullts_prompt_ids':'prompt_ids'})\n",
    "\n",
    "print(ds_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Badassie's you and Lufre's lost a place\n"
     ]
    }
   ],
   "source": [
    "# test modelu bez promptu\n",
    "# dulezite - kdyz byl tiny model natrenovany malo (jedna epocha), tak vracel dlouhe vety, ktere se opakovaly\n",
    "out1 = model.generate(torch.tensor(ds_ready[0]['input_features']).unsqueeze(0).cuda()).detach().cpu()\n",
    "print(processor.decode(out1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rar CSA One Delta Zulu established\n",
      "CSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\n",
      "three four five six zero CSA One Delta Zulu  pekný deň\n"
     ]
    }
   ],
   "source": [
    "# test modelu s promptem (1 nebo 10 epoch vyjde na stejno zda se)\n",
    "out2 = model.generate(\n",
    "    torch.tensor(ds_ready[0]['input_features']).unsqueeze(0).cuda(),\n",
    "    prompt_ids=torch.tensor(ds_ready[0]['prompt_ids']).cuda()\n",
    ").detach().cpu()\n",
    "print(processor.decode(out2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rar CSA One Delta Zulu established\n",
      "CSA One Delta Zulu  pekný deň\n",
      "real\n",
      "Oscar Kilo Uniform Tango Charlie re- release from frequency flying information service available at one two six decimal one Praha Information   dobrý den\n"
     ]
    }
   ],
   "source": [
    "# test modelu, kdy je vstup a prompt jsou od jinych nahravek\n",
    "# vysledek - neni to uplne tak, ze ten model prepsal ten prompt, ale dost se to blizi tomu\n",
    "out3 = model.generate(\n",
    "    torch.tensor(ds_ready[2]['input_features']).unsqueeze(0).cuda(),\n",
    "    prompt_ids=torch.tensor(ds_ready[0]['prompt_ids']).cuda()\n",
    ").detach().cpu()\n",
    "print(processor.decode(out3[0]))\n",
    "print('real')\n",
    "print(processor.decode(ds_ready[1]['labels'],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare decoder prompts (pad them to the same length)\n",
    "batch_decoder_inputs = processor.tokenizer.pad({\"input_ids\": ds_ready[0:2]['prompt_ids']}, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# Generate\n",
    "outputs = model.generate(\n",
    "    input_features=torch.tensor(ds_ready[0:2]['input_features']).cuda(),\n",
    "    decoder_input_ids=batch_decoder_inputs[\"input_ids\"].cuda(),\n",
    "    decoder_attention_mask=batch_decoder_inputs[\"attention_mask\"],  # Important for handling padding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftranscript|><|notimestamps|>Radar CSA One Delta Zulu established\n",
      "CSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\n",
      "\n",
      "three four five six zero CSA One Delta Zulu  pekný deň<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# print(processor.decode(out1[0]))\n",
    "print(processor.decode(ds_ready[0]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        batch[\"labels\"] = labels_batch\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(ds_ready, batch_size=3, collate_fn=data_collator)\n",
    "metr = ComputeMetrics(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(input_features).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate over batches\n",
    "all_preds = []\n",
    "all_lables = []\n",
    "for batch in dataloader:\n",
    "    input_features = batch[\"input_features\"].cuda()\n",
    "    out = model.generate(input_features).detach().cpu()\n",
    "    all_preds.extend(processor.batch_decode(out, skip_special_tokens=True))\n",
    "    all_lables.extend(processor.batch_decode(batch[\"labels\"]['input_ids'], skip_special_tokens=True))\n",
    "    # Free memory\n",
    "    del batch\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmetr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_lables\u001b[49m\u001b[43m)\u001b[49m    \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mComputeMetrics.compute_metrics\u001b[39m\u001b[34m(self, pred_text, reference_text)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# we do not want to group tokens when computing the metrics\u001b[39;00m\n\u001b[32m     13\u001b[39m pred_str = \u001b[38;5;28mself\u001b[39m.tokenizer.batch_decode(pred_ids, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m label_str = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m wer = \u001b[32m100\u001b[39m * metric.compute(predictions=pred_str, references=label_str)\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mwer\u001b[39m\u001b[33m\"\u001b[39m: wer}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3821\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.batch_decode\u001b[39m\u001b[34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[39m\n\u001b[32m   3796\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbatch_decode\u001b[39m(\n\u001b[32m   3797\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   3798\u001b[39m     sequences: Union[List[\u001b[38;5;28mint\u001b[39m], List[List[\u001b[38;5;28mint\u001b[39m]], \u001b[33m\"\u001b[39m\u001b[33mnp.ndarray\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtorch.Tensor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtf.Tensor\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   3801\u001b[39m     **kwargs,\n\u001b[32m   3802\u001b[39m ) -> List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m   3803\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3804\u001b[39m \u001b[33;03m    Convert a list of lists of token ids into a list of strings by calling decode.\u001b[39;00m\n\u001b[32m   3805\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3818\u001b[39m \u001b[33;03m        `List[str]`: The list of decoded sentences.\u001b[39;00m\n\u001b[32m   3819\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   3820\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m-> \u001b[39m\u001b[32m3821\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3822\u001b[39m \u001b[43m            \u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3823\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3824\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclean_up_tokenization_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3825\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3826\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3827\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m sequences\n\u001b[32m   3828\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py:723\u001b[39m, in \u001b[36mWhisperTokenizer.decode\u001b[39m\u001b[34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, output_offsets, time_precision, decode_with_timestamps, normalize, basic_normalize, remove_diacritics, **kwargs)\u001b[39m\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\n\u001b[32m    674\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    675\u001b[39m     token_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     **kwargs,\n\u001b[32m    685\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    686\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[33;03m    Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[33;03m    tokens and clean up tokenization spaces.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    721\u001b[39m \u001b[33;03m        `str`: The decoded sentence.\u001b[39;00m\n\u001b[32m    722\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m     filtered_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_preprocess_token_ids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m     text = \u001b[38;5;28msuper\u001b[39m().decode(\n\u001b[32m    729\u001b[39m         filtered_ids,\n\u001b[32m    730\u001b[39m         skip_special_tokens=skip_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m    735\u001b[39m         **kwargs,\n\u001b[32m    736\u001b[39m     )\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decode_with_timestamps:\n\u001b[32m    738\u001b[39m         \u001b[38;5;66;03m# legacy method to decode timestamps when not included in the tokenizer vocabulary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py:666\u001b[39m, in \u001b[36mWhisperTokenizer._preprocess_token_ids\u001b[39m\u001b[34m(self, token_ids, skip_special_tokens)\u001b[39m\n\u001b[32m    664\u001b[39m     prompt_token_id = \u001b[38;5;28mself\u001b[39m.convert_tokens_to_ids(\u001b[33m\"\u001b[39m\u001b[33m<|startofprev|>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    665\u001b[39m     decoder_start_token_id = \u001b[38;5;28mself\u001b[39m.convert_tokens_to_ids(\u001b[33m\"\u001b[39m\u001b[33m<|startoftranscript|>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     token_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strip_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_token_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_start_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.13/site-packages/transformers/models/whisper/tokenization_whisper.py:886\u001b[39m, in \u001b[36mWhisperTokenizer._strip_prompt\u001b[39m\u001b[34m(self, token_ids, prompt_token_id, decoder_start_token_id)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token_ids:\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m token_ids\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m has_prompt = \u001b[43mtoken_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m == prompt_token_id\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_prompt:\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_start_token_id \u001b[38;5;129;01min\u001b[39;00m token_ids:\n",
      "\u001b[31mTypeError\u001b[39m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "metr.compute_metrics(all_preds, all_lables)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 76.61662817551964}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.compute_metrics2(all_preds, all_lables)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = metr.compute_metrics(out[0].unsqueeze(0), batch[\"labels\"]['input_ids'][0].unsqueeze(0))\n",
    "val1 = metr.compute_metrics(out[1].unsqueeze(0), batch[\"labels\"]['input_ids'][1].unsqueeze(0))\n",
    "val2= metr.compute_metrics(out[2].unsqueeze(0), batch[\"labels\"]['input_ids'][2].unsqueeze(0))\n",
    "print(val,val1,val2,(val1['wer']+val2['wer']+val['wer'])/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.tensor(ds_ready['input_features'][:5]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model.generate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del batch\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Radar CSA One Delta Zulu established\\nCSA One Delta Zulu roger contact Ruzyne Tower one three four decimal five six zero\\n\\nthree four five six zero CSA One Delta Zulu  pekný deň'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(ds_ready[0]['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 42])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Radar CC1DZ, established CC1DZ, roger, contact roger tower 134.560 134.560, CC1DZ, take me again'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metr = ComputeMetrics(processor.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9654,   289, 12630,    16,    35,    57,    11,  7545, 12630,    16,\n",
       "           35,    57,    11,   744,  1321,    11,  3385,   744,  1321, 10567,\n",
       "         3705,    19,    13,    20,  4550,  3705,    19,    13,    20,  4550,\n",
       "           11, 12630,    16,    35,    57,    11,   747,   385,   797, 50257,\n",
       "        50257, 50257], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50258, 50363, 48444,   289,   383,  8886,  1485, 18183,  1176, 12845,\n",
       "         7545,   198,    34,  8886,  1485, 18183,  1176, 12845,   744,  1321,\n",
       "         3385, 15702,  1229,   716, 17877,   472,  1045,  1451, 26601,  1732,\n",
       "         2309,  4018,   198,   198, 27583,  1451,  1732,  2309,  4018,   383,\n",
       "         8886,  1485, 18183,  1176, 12845,   220,   520,  5457, 11822,   368,\n",
       "          129,   230, 50257])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(ds_ready[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 93.54838709677419}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.compute_metrics(out[0].unsqueeze(0), torch.tensor(ds_ready[0]['labels']).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_test = processor.tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "label_test = processor.tokenizer.batch_decode(ds_ready['labels'][:3], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wer': 78.37837837837837}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metr.compute_metrics2(out_test,label_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
