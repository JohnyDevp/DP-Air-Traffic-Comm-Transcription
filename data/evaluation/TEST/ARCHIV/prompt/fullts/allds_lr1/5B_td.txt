=========================================================
**** TRAINING RUN, datetime: 2025-04-22 16:47:32 ****
=========================================================
Training setup:
{
    "model_path": "/mnt/scratch/tmp/xholan11/models/planned-allds-fullts/30/learning_rate/lr1/checkpoint-1050",
    "continue_from_checkpoint": false,
    "train_datasets": [
        "atco_en"
    ],
    "dropout": 0.0,
    "datasets_root_dir": "/mnt/scratch/tmp/xholan11/data",
    "use_prompt": true,
    "self_prompt": false,
    "transcription_name_in_ds": "full_ts",
    "prompt_name_in_ds": "prompt_fullts_5B"
}
Training arguments:
{
    "output_dir": "/mnt/scratch/tmp/xholan11/models/PROMPT/allds_lr1/5B/",
    "per_device_train_batch_size": 4,
    "gradient_accumulation_steps": 8,
    "learning_rate": 3.125e-06,
    "warmup_ratio": 0.1,
    "weight_decay": 1e-06,
    "gradient_checkpointing": true,
    "fp16": true,
    "save_strategy": "epoch",
    "num_train_epochs": 10,
    "per_device_eval_batch_size": 8,
    "predict_with_generate": true,
    "generation_max_length": 448,
    "logging_steps": 15,
    "report_to": [
        "tensorboard"
    ],
    "metric_for_best_model": "wer",
    "greater_is_better": false,
    "push_to_hub": false
}
=========================================================
**** TRAINING RUN, datetime: 2025-04-22 16:50:13 ****
=========================================================
Training setup:
{
    "model_path": "/mnt/scratch/tmp/xholan11/models/planned-allds-fullts/30/learning_rate/lr1/checkpoint-1050",
    "continue_from_checkpoint": false,
    "train_datasets": [
        "atco_en"
    ],
    "dropout": 0.0,
    "datasets_root_dir": "/mnt/scratch/tmp/xholan11/data",
    "use_prompt": true,
    "self_prompt": false,
    "transcription_name_in_ds": "full_ts",
    "prompt_name_in_ds": "prompt_fullts_5B"
}
Training arguments:
{
    "output_dir": "/mnt/scratch/tmp/xholan11/models/PROMPT/allds_lr1/5B/",
    "per_device_train_batch_size": 4,
    "gradient_accumulation_steps": 8,
    "learning_rate": 3.125e-06,
    "warmup_ratio": 0.1,
    "weight_decay": 1e-06,
    "gradient_checkpointing": true,
    "fp16": true,
    "save_strategy": "epoch",
    "num_train_epochs": 10,
    "per_device_eval_batch_size": 8,
    "predict_with_generate": true,
    "generation_max_length": 448,
    "logging_steps": 15,
    "report_to": [
        "tensorboard"
    ],
    "metric_for_best_model": "wer",
    "greater_is_better": false,
    "push_to_hub": false
}
Training finished, datetime: 2025-04-22 18:28:34 ****
============================================
============================================

